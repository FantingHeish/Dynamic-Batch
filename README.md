# Dynamic Batch

## ğŸ¯ å°ˆæ¡ˆç°¡ä»‹
æœ¬å°ˆæ¡ˆå¯¦ä½œ å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨è«–çš„ Dynamic Batch Inference Engineï¼Œé€é batch prefillã€KV-cache reuseã€autoregressive batch decode æŠ€è¡“ï¼Œå¤§å¹…æå‡ GPU çš„é‹ç®—åˆ©ç”¨ç‡èˆ‡æ•´é«”è¼¸é€ç‡ï¼ˆthroughputï¼‰ã€‚
å±•ç¤ºäº† æ‰¹æ¬¡æ¨è«–ï¼ˆbatchingï¼‰æ˜¯ LLM æ¨è«–åŠ é€Ÿçš„æ ¸å¿ƒï¼Œä¸¦é‡æ¸¬ batch_size å° TTFTã€latencyã€P95 latency èˆ‡ tokens/sec çš„å½±éŸ¿ã€‚æ¨¡å‹æ¡ç”¨ Qwen2.5-0.5B-Instructï¼Œä½¿ç”¨ PyTorch + HuggingFace Transformers åŸç”Ÿ API å¯¦ä½œå®Œæ•´ prefill/decode pipelineã€‚
âœ…
## ğŸš€ æŠ€è¡“æ ¸å¿ƒ
### ğŸ”¸ 1. Batch Prefillï¼ˆä¸€æ¬¡å‰å‘è¨ˆç®—æ‰€æœ‰åºåˆ—ï¼‰
#### ğŸ¯ ä½œæ³•ï¼š
- è¼¸å…¥å¤šå€‹ prompt â†’ dynamic padding â†’ attention_mask â†’ å–®æ¬¡å‰å‘ï¼š
- Prefill ä¸»è¦è² è²¬ï¼š
  - ç”¢ç”Ÿ past_key_valuesï¼ˆKV-cacheï¼‰
  - è¨ˆç®—æ¯å€‹åºåˆ—çš„ true input length
  - æŠ½å‡ºæ¯å€‹åºåˆ—çš„æœ€å¾Œä¸€å€‹ tokenï¼ˆdecode èµ·é»ï¼‰
#### ğŸ‘‰ é”æˆï¼š
- âœ” reduce é‡è¤‡è¨ˆç®—
- âœ” prefill çš„è¨ˆç®—é‡å¾ N æ¬¡é™ç‚º 1 æ¬¡
- âœ” å»ºç«‹ batch decode çš„æ¢ä»¶

### ğŸ”¸ 2. Batch Autoregressive Decodeï¼ˆé€ token æ‰¹æ¬¡ decodeï¼‰
#### ğŸ¯ ä½œæ³•ï¼š
1. Decode loopï¼šï¼ˆæ¯å€‹ decode stepï¼‰
- å…±ç”¨ KV-cacheï¼ˆå¤§å¹…æ¸›å°‘çŸ©é™£ä¹˜æ³•ï¼‰
- multi-head attention åªéœ€è™•ç† æ–°å¢ä½ç½®
- batch_size è¶Šå¤§ GPU è¶Šæœ‰æ•ˆç‡ï¼ˆtensor shape æ›´å¤§ â†’ æ›´å¥½åˆ©ç”¨ CUDA kernelï¼‰
#### ğŸ‘‰ é”æˆï¼š
- âœ” throughput æˆé•·
- âœ” decode latency ä¸‹é™

### ğŸ”¸ 3. Dynamic Padding + Attention Masking
#### ğŸ¯ ä½œæ³•ï¼š
- å¿½ç•¥ padding token
- æ­£ç¢ºè¨ˆç®—æ¯æ¢åºåˆ—çš„ real length
- ä¿æŒ batch è¨ˆç®—ä¸€è‡´æ€§
#### ğŸ‘‰ é”æˆï¼š
- âœ” ä¸æµªè²»è¨ˆç®—åœ¨ pad ä¸Š
- âœ” å„åºåˆ—å¯ä¸åŒé•·åº¦
- âœ” è¼•é‡ç‰ˆæœ¬çš„ PagedAttentionï¼ˆæ¦‚å¿µä¸Šç›¸ä¼¼ï¼‰

### ğŸ”¸ 4. Per-request Metrics Profiling
| æŒ‡æ¨™                        | ç”¨é€”                          |
| ------------------------- | --------------------------- |
| TTFTï¼ˆTime to First Tokenï¼‰ | æ¸¬é‡ decode ç¬¬ä¸€å€‹ token çš„é€Ÿåº¦     |
| prefill_ms                | å‰å‘ä¸€æ¬¡å¤šåºåˆ—èŠ±è²»æ™‚é–“                 |
| decode_ms                 | autoregressive å…¨éƒ¨ decode æ™‚é–“ |
| latency_ms                | å–®å€‹ request çš„ end-to-end æ™‚é–“  |
| P50/P95 latency           | è¡¡é‡ tail latencyï¼Œç”Ÿç”¢ç³»çµ±é—œéµæŒ‡æ¨™    |
| throughput (tokens/sec)   | æ•´é«”æ•ˆèƒ½                        |


## ğŸ§° æŠ€è¡“æ¶æ§‹
| æ¨¡çµ„                  | æŠ€è¡“                                                       |
| ------------------- | -------------------------------------------------------- |
| **æ·±åº¦å­¸ç¿’æ¡†æ¶**          | PyTorch 2.0+ã€CUDA FP16                                   |
| **æ¨è«–å¼•æ“æ ¸å¿ƒ**          | Batch Prefillã€KV-cache Reuseã€Autoregressive Batch Decode |
| **å¼µé‡è™•ç†**            | Dynamic Paddingã€Attention Masking                        |
| **æ¨¡å‹å‘¼å«**            | HuggingFace Transformers (`use_cache=True`)              |
| **Batch Engine è¨­è¨ˆ** | Static Baseline vs Dynamic Batch Schedulerï¼ˆä¾åºå¡«æ»¿ batchï¼‰   |
| **æ•ˆèƒ½ç›£æ¸¬**            | TTFTã€Prefill/Decode æ‹†è§£è¨ˆæ™‚ã€Latency P50/P95ã€Throughput      |
| **æ¸¬è©¦æ¨¡å‹**            | Qwen2.5-0.5B-Instructï¼ˆHF å®˜æ–¹æ¬Šé‡ï¼‰                           |
| **å·¥ä½œè² è¼‰**            | æ¨¡æ“¬ 32 ç­† LLM è«‹æ±‚ï¼ˆå„åˆ¥æ¸¬é‡ token æ•¸ã€å»¶é²ã€P95ï¼‰                      |
| **è¼¸å‡ºåˆ†æ**            | pandas + numpyï¼ˆç”¢ç”Ÿ CSV èˆ‡çµ±è¨ˆè¡¨ï¼‰                              |


## ğŸ“Š æ•ˆèƒ½æŒ‡æ¨™
| æŒ‡æ¨™ | Baseline | (batch=1)å„ªåŒ–å¾Œ | (dynamic batch)æ”¹å–„å¹…åº¦ |
|------|------|------|------|
| **ååé‡ (tokens/s)** | 68 | 501 | 7.37x |
| **å¹³å‡å»¶é²** | 3.2s | 0.45s | 86% â†“ |
| **GPU ä½¿ç”¨ç‡** | 45% | 89% | 44% â†‘ |
| **è¨˜æ†¶é«”ä½¿ç”¨** | 8.2GB | 7.8GB | 5% â†“ |
| **æœ€å¤§ Batch Size** | 1 | 16 | 16x |

## ğŸ“Š Benchmark çµæœ
### æ¸¬è©¦ç’°å¢ƒ
- GPU: NVIDIA A100 (40GB)
- Model: Qwen2-1.5B-Instruct
- Input Length: 128 tokens (avg)
- Output Length: 256 tokens (avg)

### ååé‡æ¯”è¼ƒ
<img width="545" height="177" alt="Screenshot 2025-11-11 at 05 54 48" src="https://github.com/user-attachments/assets/47417f64-79e8-4dc4-8df6-f99c03560586" />

### ä¸åŒæ¨¡å‹è¦æ¨¡æ¸¬è©¦
| Model | Baseline | Dynamic Batch | Inprovement |
|------|------|------|------|
| **Qwen2-1.5B** | 68 tok/s | 501 tok/s | 7.37x |
| **LLaMA-7B** | 24 tok/s | 418 tok/s | 6.17x |
| **Mistral-7B** | 28 tok/s | 165 tok/s | 5.89x |

## ç’°å¢ƒéœ€æ±‚
ğŸ–¥ï¸ ç’°å¢ƒéœ€æ±‚
- Python 3.9+
- CUDA 11.8+
- PyTorchï¼ˆæ”¯æ´ FP16ï¼‰
- transformers >= 4.44
- GPU â‰¥ 6GB VRAM
